{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중선형회귀\n",
    "수치형(실수형) 설명변수 X와 연속형 숫자로 이루어진 종속변수 Y간의 관계를 선형으로 가정하고 이를 가장 잘 표현할 수 있는 회귀계수(beta)를 데이터로부터 추정하는 모델\n",
    "```\n",
    "예시: 주택크기(X1)와 주택가격(Y)의 관계를 나타내는 직선을 찾는(어떤 관계에 있는지 찾는) 문제\n",
    "```\n",
    "* 범주형 : [0,1,2]와 같은 클래스 라벨링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 계수 결정법\n",
    "* Direct Solution : 미분\n",
    "    - 선형회귀 계수들은 실제값(Y)과 모델 예측값(Y')의 차이인 오차제곱합(error sum of squares)을 최소로 하는 값을 회귀 계수로 선정\n",
    "    - 최적의 계수들은 **회귀 계수에 대해 미분한 식을 0**으로 놓고 풀면 명시적인 해를 구할 수 있다.\n",
    "* Numerical Search : 미분이 불가능하다던지?!\n",
    "    - Gradient descent(경사하강법) 같은 반복적인 방식으로 선형회귀 계수를 구함.\n",
    "    - **Gradient descent**: 어떤 함수 값(목적 함수, 비용 함수, 에러 값: 최소화하고자 하는 것!!!)을 최소화 하기 위해 \n",
    "        - 임의의 시작점을 잡는다.\n",
    "        - 해당 지점에서의 gradient(경사)를 구한다.\n",
    "        - Gradient의 반대 방향으로 조금씩 이동하는 과정을 여러 번 반복한다.\n",
    "        > 이동하는 정도는 learning rate로 나타내고, 이 과정은 더 이상 변화가 없을 때 까지 반복한다.\n",
    "\n",
    "### Gradient descent의 종류\n",
    "<img src=https://user-images.githubusercontent.com/53554014/95410143-20fd9e80-095e-11eb-8273-543089398678.png width=90% alt=GD></img>\n",
    "* Batch Gradient Descent(GD)\n",
    "    - 파라미터를 업데이트 할 때마다 **모든 학습 데이터를 사용하여** cost function의 gradient를 계산\n",
    "    - 가장 naive하고 기본적인 방법이기 때문에 Vanilla Gradient Descent라 불린다.\n",
    "    - 데이터가 많으면 속도가 매우 느리다!!! 따라서 매우 낮은 학습 효율을 보일 수 있다.\n",
    "* Stochastic Gradient Descent(SGD)\n",
    "    - 파라미터를 업데이트 할 때, **무작위로 샘플링된 학습 데이터를 하나씩만 사용**하여 cost function의 gradient를 계산\n",
    "    - 장점: 모델을 자주 업데이트 하며, 성능 개선 정도를 빠르게 확인 가능. Local minima에 빠질 가능성을 줄일 수 있음.\n",
    "    - 단점: 최소 cost에 수렴했는지의 판단이 상대적으로 어려움\n",
    "    > 데이터 전체를 보는 것이 아니기 때문!!! 최소 cost에 가까워지고 있긴 한데 그 점이 최소 cost인지는 알 수 없음. 그러나 충분하다는 것이 수학적으로 증명되었으므로 사용되는 것!\n",
    "* Mini Batch Gradient Descent\n",
    "    - 파라미터를 업데이트 할 때마다 **일정량의 일부 데이터를 무작위로 뽑아** cost function의 gradient를 계산.\n",
    "    - Batch Gradient Descent와 Stochastic Gradient Descent 개념의 혼합이다.\n",
    "    - SGD의 노이즈를 줄이면서, GD의 전체 배치보다 효율적이다. 가장 널리 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화(regularization)\n",
    "회귀계수가 가질 수 잇는 값에 제약조건을 부여하여 미래 데이터에 대한 오차를 잘 해결할 수 있기를 기대\n",
    "* 미래데이터에 대한 오차의 기대 값은 모델의 Bias와 Variance로 분해 가능.\n",
    "* 정규화는 **Variance를 감소**시켜 일반화 성능을 높이는 기법.\n",
    "> 단, 이 과정에서 bias가 증가할 수 있다.\n",
    "* <img src=\"https://user-images.githubusercontent.com/53554014/95421493-79da3080-0978-11eb-9e8e-31c545d7ec35.png\" width=50% alt=\"regularization\"></img>\n",
    "    * 정규화가 거의 없을 때 : overfitting(학습데이터는 정말 잘 맞추고 있지만, 미래 데이터가 조금만 바뀌어도 예측 값이 들쭉날쭉.\n",
    "    * 강한 수준의 정규화 : 학습데이터에 대한 설명력은 다소 포기하는 대신 미래 데이터 변화에 상대적으로 안정적인 결과를 나타냄.\n",
    "\n",
    "### Bias-Variance Decomposition\n",
    "일반화(generalization) 성능을 높이는 정규화(Regularization), 앙상블(ensemble)기법의 이론적 배경으로, 학습에 쓰지 않은 미래데이터에 대한 오차의 기대값을 모델의 Bias와 Variacne로 분해하자는 내용.\n",
    "\n",
    "<img src=https://user-images.githubusercontent.com/53554014/95420998-72feee00-0977-11eb-9d99-a4e4ade4387a.png width=80% alt=\"variance\"></img>\n",
    "* 앞 두 그림은 분산이 큰 상황, 뒤 두 그림은 분산이 작은 상황.\n",
    "* 1,3 그림은 bias가 큰 상황, 2,4 그림은 bias가 작은 상황.\n",
    "* 위 그림을 비교하면, bias를 줄였을 때 정답을 맞출 확률은 분산이 작은 상황에서이다.\n",
    "* **즉, 정규화는 variance를 감소시켜 정답을 맞출 확률을 증가시키는(성능을 높이는) 방법이다!**\n",
    "> 물론 과녁 밖으로 bias를 증가시키지 않도록 정규화를 잘 컨트롤 해야 한다.\n",
    "* `정규화 정도(C) = 1/lambda` \n",
    "* C를 키우면 강한 정규화가 된다. C값을 hand-tunning하여 적절한 값을 설정한다.\n",
    "* Boosting은 Bias를 줄여 성능을 높이고, Lasso regression(라쏘회귀)는 Variance를 줄여 성능을 높이는 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "다중선형회귀의 정의를 다시 생각해보자! 수치형 설명변수(X)와 연속형 숫자로 이루어진 종속변수(Y) 간의 관계를 선형으로 가정하고 이를 가장 잘 표현할 수 있는 회귀계수(beta)를 데이터로부터 추정하는 것.\n",
    "\n",
    "* 예시 1: 성인 여성의 나이와 혈압 관계\n",
    "    - 33명의 성인 여성에 대한 나의와 혈압 데이터가 있다.\n",
    "    - 오차제곱합을 최소로 하는 회귀 계수 계산 결과는 다음과 같다. `Y = 81.54 + 1.222AGE`\n",
    "    - 나이 변수에 대응하는 계수는 1.222로 구해졌다. 즉, 나이를 한 살 더 먹으면 혈압이 1.222mm/Hg만큼 증가한다.\n",
    "<img src=https://user-images.githubusercontent.com/53554014/95422188-ceca7680-0979-11eb-8457-984cf3371136.png width=50%></img>\n",
    "\n",
    "* 예시 2: 성인 여성의 나이와 암 발병 관계\n",
    "    - 33명의 성인 여성에 대한 나이(AGE)병(CD) 데이터가 있다.\n",
    "    - 암 발병 여부는 정상을 0, 발병을 1이라 하자.\n",
    "    > 범주형 숫자(암 발병 여부)는 연속형 숫자(혈압)과 달리 의미를 지니지 않는다. 따라서 정상을 1, 발병을 0이라 해도 상관 없음.\n",
    "    - 오차제곱합을 최소로 하는 회귀 계수를 계산해보자.\n",
    "    - 어떻게?\n",
    "<img src=\"https://user-images.githubusercontent.com/53554014/95422386-3254a400-097a-11eb-8a7c-c6bcaa598789.png\" width=50%></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 우선 관련 개념을 알아보자!!\n",
    "### Logistic function\n",
    "<img src=\"https://user-images.githubusercontent.com/53554014/95422660-a98a3800-097a-11eb-8cd6-192177e69bae.png\" width=80%></img>\n",
    "* 위와 같은 S-커브 함수를 로지스틱 함수라 한다.\n",
    "    * 실제 많은 자연/사회현상에서는 특정 변수에 대한 확률 값이 선형이 아닌 위와 같은 S-커브 형태이다.\n",
    "* x값은 어떤 값이든 받을 수 있다.\n",
    "* y값(출력 결과)는 항상 0에서 1 사이 값이다.\n",
    "* 오잉? 이 조건은 확률밀도함수(probability density function)으로서의 요건을 충족한다!!\n",
    "* **시그모이드 함수라고도 부른다.**\n",
    "\n",
    "### Odds(승산)\n",
    "<img src=\"https://user-images.githubusercontent.com/53554014/95423010-4fd63d80-097b-11eb-914c-ce23b2e31530.png\" width=30%></img>\n",
    "<img src=\"https://user-images.githubusercontent.com/53554014/95423151-9461d900-097b-11eb-8555-68c461969fc4.png\" width=30%></img>\n",
    "* P(A)가 1에 가까울수록 승산은 커진다.\n",
    "* P(A)가 0이면 승산은 0이다.\n",
    "* P(A)는 0과 1 사이의 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이항 로지스틱 회귀\n",
    "아까와 같이 Y가 범주형이라서 다중선형회귀모델을 적용하지 못하는 경우로 돌아가자. Y를 확률식으로 바꾸고 승산으로 바꾸고 로그를 취하고 어쩌구저쩌구하면 **로지스틱 함수**가 나온다!!!\n",
    "* 회귀 문제로 풀 수 없는 문제를 풀기 위해 Odd, log로 범위를 bound 시켰더니 로지스틱 함수가 나왔다.\n",
    "* 즉, 범주형 데이터의 분류 문제를 풀 수 있게 되었다!!!\n",
    "* 이것을 **로지스틱 회귀**라 부른다.\n",
    "\n",
    "### 결정 경계\n",
    "이항 로지스틱 모델은 범주 정보를 모르는 입력 벡터 x를 넣으면 범주 1에 속할 확률을 반환한다. **`beta.T * x > 0`이면 범주를 1**로 분류, **`beta.T * x < 0`이면 범주를 0**으로 분류한다.\n",
    "* `beta.T * x = 0` 일 때 1인지 0인지 결정하는 로지스틱 결정 경계(decision boundary)인 하이퍼플레인(hyperplane)이다.\n",
    "\n",
    "### 다항 로지스틱 회귀\n",
    "이항 로지스틱 회귀 모델은 결국 집합을 통한 확률 문제이다. 따라서 3항 로지스틱 회귀 문제가 있을 때, 3번 범주는 1번과 2번 집합으로 표현할 수 있다.\n",
    "\n",
    "즉, 3번 범주에 속할 확률은 1- (1번 범주에 속할 확률) - (2번 범주에 속할 확률)이다.\n",
    "* 이를 통해 K개 범주를 분류하는 다항 로지스틱 회귀 모델의 입력 벡터 x가 각 클래스로 분류될 확률을 구할 수 있다.\n",
    "* <img src=\"https://user-images.githubusercontent.com/53554014/95424363-7a28fa80-097d-11eb-8c3d-3273ca725404.png\" width=80%></img>\n",
    "* 또 어쩌구저쩌구 하면 로그 성질을 활용해 c번째 범주에 속할 확률을 기준으로 식을 정리할 수 있다.\n",
    "* <img src=\"https://user-images.githubusercontent.com/53554014/95424528-bb210f00-097d-11eb-81d6-1de19839eb70.png\" width=90%></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀 실습\n",
    "### (1) iris 데이터로 실습\n",
    "* 로지스틱 회귀를 적용해본다.\n",
    "* 전처리 과정에 정규화를 적용해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "print(iris.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width\n",
      "0           5.1          3.5           1.4          0.2\n"
     ]
    }
   ],
   "source": [
    "X = iris.drop('species', axis=1)\n",
    "print(X.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149    virginica\n",
      "Name: species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = iris['species']\n",
    "print(y.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "classle = LabelEncoder()\n",
    "y = classle.fit_transform(iris['species'].values)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 드디어 Logistic regression 적용 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logit = LogisticRegression(C=200, random_state=11) #C랑 random state값만 설정하고 나머지 params는 default로 둔다!\n",
    "l_1 = Logit.fit(X_train_std, y_train)\n",
    "y_train_pred = Logit.predict(X_train_std)\n",
    "y_test_pred = Logit.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9809523809523809\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train, y_train_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) wine data로 실습\n",
    "* 데이터 전처리 중 정규화를 적용한다.\n",
    "* 정규화의 규제강도(C, variance 정도를 조절)를 다양하게 해서 실험한다.\n",
    "* 다양한 규제강도에 따라 회귀계수가 어떻게 변하는지 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',header=None)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/53554014/95431924-ebba7600-0988-11eb-8725-0863f047cd66.png\" width=80%></img>\n",
    "<img src=\"https://user-images.githubusercontent.com/53554014/95431989-ff65dc80-0988-11eb-87cc-bc6fba0f736e.png\" width=80%></img>\n",
    "* header를 없애거나 0으로하면 0번 row의 내용이 헤더로 들어가지더라.\n",
    "* 즉, 이 데이터는 원래 헤더가 수치형 데이터인 것이다!\n",
    "* 하지만 뭐가 뭔지 모르겠으니 헤더를 붙여보겠음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class label</th>\n",
       "      <th>alchohol</th>\n",
       "      <th>malic acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity of ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD208</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class label  alchohol  malic acid   ash  alcalinity of ash  magnesium  \\\n",
       "0            1     14.23        1.71  2.43               15.6        127   \n",
       "1            1     13.20        1.78  2.14               11.2        100   \n",
       "2            1     13.16        2.36  2.67               18.6        101   \n",
       "3            1     14.37        1.95  2.50               16.8        113   \n",
       "4            1     13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   total phenols  flavanoids  nonflavanoid phenols  proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   color intensity   hue  OD208  proline  \n",
       "0             5.64  1.04   3.92     1065  \n",
       "1             4.38  1.05   3.40     1050  \n",
       "2             5.68  1.03   3.17     1185  \n",
       "3             7.80  0.86   3.45     1480  \n",
       "4             4.32  1.04   2.93      735  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.columns = ['class label', 'alchohol', 'malic acid', 'ash', 'alcalinity of ash', 'magnesium', 'total phenols', \n",
    "                    'flavanoids', 'nonflavanoid phenols', 'proanthocyanins', 'color intensity', 'hue', \n",
    "                    'OD208', 'proline']  # Column names\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check class label:  [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print('Check class label: ', np.unique(wine['class label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n"
     ]
    }
   ],
   "source": [
    "#feature\n",
    "X_ = wine.iloc[:, 1:].values #class label 빼고\n",
    "print(X_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "#label\n",
    "y_ = wine.iloc[:, 0].values #class label만 가져오기\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_, y_, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "X_train2_std = std.fit_transform(X_train2)\n",
    "X_test2_std = std.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with L2 or L1 regularizaion\n",
    "* Logistic regression params 중 penalty는 l1, l2가 있다.\n",
    "* sckit-learn docs에서 확인하면 default가 l2라고 한다.\n",
    "* 봐도 뭔차인지 잘 모르겠다. 실험해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_10 = LogisticRegression(penalty='l2', C=10.0, solver='saga')\n",
    "lr2_1 = LogisticRegression(penalty='l2', C=1.0, solver='saga')\n",
    "lr2_0_1 = LogisticRegression(penalty='l2', C=0.1, solver='saga')\n",
    "\n",
    "lr1_10 = LogisticRegression(penalty='l1', C=10.0, solver='saga')\n",
    "lr1_1 = LogisticRegression(penalty='l1', C=1.0, solver='saga')\n",
    "lr1_0_1 = LogisticRegression(penalty='l1', C=0.1, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy with L2 and λ=0.1: 1.0\n",
      "Test accuracy with L2 and λ=0.1: 0.9814814814814815\n",
      "=============================================\n",
      "Training accuracy with L2 and λ=1: 1.0\n",
      "Test accuracy with L2 and λ=1: 0.9814814814814815\n",
      "=============================================\n",
      "Training accuracy with L2 and λ=10: 1.0\n",
      "Test accuracy with L2 and λ=10: 1.0\n",
      "=============================================\n",
      "Training accuracy with L1 and λ=0.1: 1.0\n",
      "Test accuracy with L1 and λ=0.1: 0.9814814814814815\n",
      "=============================================\n",
      "Training accuracy with L1 and λ=1: 1.0\n",
      "Test accuracy with L1 and λ=1: 1.0\n",
      "=============================================\n",
      "Training accuracy with L1 and λ=10: 0.967741935483871\n",
      "Test accuracy with L1 and λ=10: 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 규제화 방법(L2 or L1)과 규제강도(λ)를 바꿔가며 accuracy score 계산\n",
    "lr2_10.fit(X_train2_std, y_train2)\n",
    "print('Training accuracy with L2 and λ=0.1:', lr2_10.score(X_train2_std, y_train2))\n",
    "print('Test accuracy with L2 and λ=0.1:', lr2_10.score(X_test2_std, y_test2))\n",
    "print('=============================================')\n",
    "\n",
    "lr2_1.fit(X_train2_std, y_train2)  # warning..\n",
    "print('Training accuracy with L2 and λ=1:', lr2_1.score(X_train2_std, y_train2))\n",
    "print('Test accuracy with L2 and λ=1:', lr2_1.score(X_test2_std, y_test2))\n",
    "print('=============================================')\n",
    "\n",
    "lr2_0_1.fit(X_train2_std, y_train2)\n",
    "print('Training accuracy with L2 and λ=10:', lr2_0_1.score(X_train2_std, y_train2))\n",
    "print('Test accuracy with L2 and λ=10:', lr2_0_1.score(X_test2_std, y_test2))\n",
    "print('=============================================')\n",
    "\n",
    "lr1_10.fit(X_train2_std, y_train2)\n",
    "print('Training accuracy with L1 and λ=0.1:', lr1_10.score(X_train2_std, y_train2))\n",
    "print('Test accuracy with L1 and λ=0.1:', lr1_10.score(X_test2_std, y_test2))\n",
    "print('=============================================')\n",
    "\n",
    "lr1_1.fit(X_train2_std, y_train2)\n",
    "print('Training accuracy with L1 and λ=1:', lr1_1.score(X_train2_std, y_train2))\n",
    "print('Test accuracy with L1 and λ=1:', lr1_1.score(X_test2_std, y_test2))\n",
    "print('=============================================')\n",
    "\n",
    "lr1_0_1.fit(X_train2_std, y_train2)\n",
    "print('Training accuracy with L1 and λ=10:', lr1_0_1.score(X_train2_std, y_train2))\n",
    "print('Test accuracy with L1 and λ=10:', lr1_0_1.score(X_test2_std, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 표준화 한 거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34687747  0.6116177  -0.95849517]\n",
      "[ 0.28376961  0.60389342 -0.88766303]\n",
      "[ 0.06854008  0.45692041 -0.52546049]\n",
      "[[ 1.26438645  0.14369575  0.3931559  -1.5511601   0.07439926  0.43584438\n",
      "   0.78860112 -0.26279888  0.0945389   0.14698419  0.06989391  0.98894165\n",
      "   1.37161325]\n",
      " [-1.55007846 -0.43963166 -1.21922536  1.21331351 -0.33212444 -0.58956151\n",
      "   0.89834861  0.3903272   0.38197119 -1.32239436  1.14993916  0.04747768\n",
      "  -1.75150968]\n",
      " [ 0.28569201  0.29593591  0.82606946  0.33784659  0.25772518  0.15371713\n",
      "  -1.68694973 -0.12752832 -0.4765101   1.17541017 -1.21983307 -1.03641933\n",
      "   0.37989644]]\n",
      "[[ 0.75467313  0.06155814  0.23319398 -0.89238599  0.02639075  0.29447012\n",
      "   0.56079275 -0.20731033  0.13438187  0.127967    0.10217418  0.61795312\n",
      "   0.90928163]\n",
      " [-0.98664826 -0.32320644 -0.65180091  0.66772511 -0.22942603 -0.2069493\n",
      "   0.438132    0.19828961  0.24428612 -0.78016792  0.63732618  0.08576925\n",
      "  -1.03440895]\n",
      " [ 0.23197512  0.2616483   0.41860693  0.22466087  0.20303528 -0.08752082\n",
      "  -0.99892474  0.00902072 -0.37866799  0.65220092 -0.73950036 -0.70372237\n",
      "   0.12512733]]\n",
      "[[ 0.41027557 -0.03151224  0.13676523 -0.41132897  0.05381654  0.22359637\n",
      "   0.31669714 -0.1596633   0.11371869  0.07038097  0.11107458  0.30980237\n",
      "   0.51688413]\n",
      " [-0.5426578  -0.20155832 -0.25667001  0.28071316 -0.14836726 -0.04059072\n",
      "   0.12454564  0.08289241  0.10088759 -0.44572796  0.27319971  0.09646292\n",
      "  -0.51870377]\n",
      " [ 0.13238223  0.23307056  0.11990477  0.13061582  0.09455072 -0.18300566\n",
      "  -0.44124278  0.07677088 -0.21460628  0.37534699 -0.38427429 -0.40626529\n",
      "   0.00181964]]\n"
     ]
    }
   ],
   "source": [
    "# L2 규제의 규제강도(C=1/λ)를 바꿔가며 계수 추정치 관찰\n",
    "print(lr2_10.intercept_)\n",
    "print(lr2_1.intercept_)\n",
    "print(lr2_0_1.intercept_)\n",
    "\n",
    "print(lr2_10.coef_)\n",
    "print(lr2_1.coef_)\n",
    "print(lr2_0_1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30387148  0.62186574 -0.92573722]\n",
      "[ 0.28720449  0.54039448 -0.82759897]\n",
      "[ 0.05083191  0.30693661 -0.35776852]\n",
      "[[ 1.22451204  0.          0.21299962 -1.64673615  0.          0.30292107\n",
      "   0.78416119 -0.0943716   0.          0.          0.          0.90537236\n",
      "   1.4940377 ]\n",
      " [-1.78538978 -0.44071911 -1.46934509  1.08895271 -0.3436277  -0.43908924\n",
      "   0.72571716  0.45205766  0.21605529 -1.42500777  1.12651106  0.\n",
      "  -1.92864578]\n",
      " [ 0.0344016   0.15138763  0.72884836  0.03045648  0.1979475   0.\n",
      "  -2.02822934  0.         -0.28940592  1.28082838 -1.19926126 -0.9399915\n",
      "   0.        ]]\n",
      "[[ 0.02079699  0.          0.         -1.17901171  0.          0.\n",
      "   0.02457892  0.          0.          0.          0.          0.62602817\n",
      "   0.99200519]\n",
      " [-1.5770983  -0.14580899 -0.76929873  0.03925027 -0.07014656  0.\n",
      "   0.          0.1332569   0.         -1.0335989   0.21909558  0.\n",
      "  -1.19981459]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "  -2.0675831   0.         -0.03705152  0.23444521 -0.81483593 -0.67009404\n",
      "   0.        ]]\n",
      "[[ 0.          0.          0.         -0.04187109  0.          0.\n",
      "   0.23312365  0.          0.          0.          0.          0.\n",
      "   0.84036181]\n",
      " [-0.8348109   0.          0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.42342394  0.          0.\n",
      "  -0.20652298]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "  -0.60073047  0.          0.          0.10474291 -0.35230629 -0.52170718\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# L1 규제의 규제강도(C=1/λ)를 바꿔가며 계수 추정치 관찰\n",
    "print(lr1_10.intercept_)\n",
    "print(lr1_1.intercept_)\n",
    "print(lr1_0_1.intercept_)\n",
    "\n",
    "print(lr1_10.coef_)\n",
    "print(lr1_1.coef_)\n",
    "print(lr1_0_1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 표준화 안 한 거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy with L2 and λ=0.1: 0.717741935483871\n",
      "Test accuracy with L2 and λ=0.1: 0.6296296296296297\n",
      "\n",
      "\n",
      "Training accuracy with L2 and λ=1: 0.717741935483871\n",
      "Test accuracy with L2 and λ=1: 0.6296296296296297\n",
      "\n",
      "\n",
      "Training accuracy with L2 and λ=10: 0.717741935483871\n",
      "Test accuracy with L2 and λ=10: 0.6296296296296297\n",
      "\n",
      "\n",
      "Training accuracy with L1 and λ=0.1: 0.717741935483871\n",
      "Test accuracy with L1 and λ=0.1: 0.6296296296296297\n",
      "\n",
      "\n",
      "Training accuracy with L1 and λ=1: 0.717741935483871\n",
      "Test accuracy with L1 and λ=1: 0.6296296296296297\n",
      "\n",
      "\n",
      "Training accuracy with L1 and λ=10: 0.7016129032258065\n",
      "Test accuracy with L1 and λ=10: 0.6111111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\NRL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr2_10.fit(X_train2, y_train2)\n",
    "print('Training accuracy with L2 and λ=0.1:', lr2_10.score(X_train2, y_train2))\n",
    "print('Test accuracy with L2 and λ=0.1:', lr2_10.score(X_test2, y_test2))\n",
    "print('\\n')\n",
    "\n",
    "lr2_1.fit(X_train2, y_train2)  # warning..\n",
    "print('Training accuracy with L2 and λ=1:', lr2_1.score(X_train2, y_train2))\n",
    "print('Test accuracy with L2 and λ=1:', lr2_1.score(X_test2, y_test2))\n",
    "print('\\n')\n",
    "\n",
    "lr2_0_1.fit(X_train2, y_train2)\n",
    "print('Training accuracy with L2 and λ=10:', lr2_0_1.score(X_train2, y_train2))\n",
    "print('Test accuracy with L2 and λ=10:', lr2_0_1.score(X_test2, y_test2))\n",
    "print('\\n')\n",
    "\n",
    "lr1_10.fit(X_train2, y_train2)\n",
    "print('Training accuracy with L1 and λ=0.1:', lr1_10.score(X_train2, y_train2))\n",
    "print('Test accuracy with L1 and λ=0.1:', lr1_10.score(X_test2, y_test2))\n",
    "print('\\n')\n",
    "\n",
    "lr1_1.fit(X_train2, y_train2)\n",
    "print('Training accuracy with L1 and λ=1:', lr1_1.score(X_train2, y_train2))\n",
    "print('Test accuracy with L1 and λ=1:', lr1_1.score(X_test2, y_test2))\n",
    "print('\\n')\n",
    "\n",
    "lr1_0_1.fit(X_train2, y_train2)\n",
    "print('Training accuracy with L1 and λ=10:', lr1_0_1.score(X_train2, y_train2))\n",
    "print('Test accuracy with L1 and λ=10:', lr1_0_1.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.92149645e-04  4.76995255e-04  1.51543899e-05]\n",
      "[-4.92147046e-04  4.76225444e-04  1.59216018e-05]\n",
      "[-4.90606601e-04  4.73833618e-04  1.67729834e-05]\n",
      "[[-0.00541606 -0.00179518 -0.00102293 -0.013475   -0.03574674 -0.00017599\n",
      "   0.00071245 -0.00032964 -0.00022964 -0.00256258 -0.00027028 -0.00026517\n",
      "   0.00527932]\n",
      " [ 0.00439105 -0.00064046  0.00084564  0.01043136  0.02950515  0.00128319\n",
      "   0.00170589  0.00017849  0.00101575 -0.00351984  0.00082466  0.00218502\n",
      "  -0.00444707]\n",
      " [ 0.00102501  0.00243564  0.00017728  0.00304364  0.0062416  -0.0011072\n",
      "  -0.00241834  0.00015115 -0.00078612  0.00608241 -0.00055437 -0.00191985\n",
      "  -0.00083224]]\n",
      "[[-0.00540943 -0.00178909 -0.0010181  -0.013441   -0.03566805 -0.00017515\n",
      "   0.00072044 -0.0003306  -0.00022342 -0.00257069 -0.00027117 -0.00025838\n",
      "   0.00526998]\n",
      " [ 0.00437812 -0.00064847  0.00083951  0.01034745  0.02947861  0.00128119\n",
      "   0.00169376  0.00017728  0.00100953 -0.0035312   0.00082744  0.00217277\n",
      "  -0.0044424 ]\n",
      " [ 0.00103131  0.00243756  0.00017859  0.00309354  0.00618944 -0.00110604\n",
      "  -0.0024142   0.00015331 -0.00078611  0.00610189 -0.00055627 -0.00191438\n",
      "  -0.00082758]]\n",
      "[[-0.00539201 -0.00177973 -0.00101798 -0.01344691 -0.03572694 -0.00017589\n",
      "   0.00071456 -0.00032958 -0.00023022 -0.00255278 -0.00027007 -0.00026002\n",
      "   0.00527762]\n",
      " [ 0.00435062 -0.0006532   0.00083555  0.01033943  0.02954619  0.00127809\n",
      "   0.00170128  0.00017538  0.00101244 -0.00353752  0.00082415  0.00217665\n",
      "  -0.00445089]\n",
      " [ 0.00104139  0.00243293  0.00018243  0.00310749  0.00618075 -0.00110221\n",
      "  -0.00241584  0.0001542  -0.00078222  0.0060903  -0.00055407 -0.00191663\n",
      "  -0.00082672]]\n"
     ]
    }
   ],
   "source": [
    "#L2의 규제강도 C를 바꿔가며 계수 추정치 관찰\n",
    "print(lr2_10.intercept_)\n",
    "print(lr2_1.intercept_)\n",
    "print(lr2_0_1.intercept_)\n",
    "\n",
    "print(lr2_10.coef_)\n",
    "print(lr2_1.coef_)\n",
    "print(lr2_0_1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.90894184e-04  4.75380914e-04  1.55132702e-05]\n",
      "[-4.91381998e-04  4.74401996e-04  1.69800021e-05]\n",
      "[-4.97778873e-04  4.78913410e-04  1.88654625e-05]\n",
      "[[-0.005397   -0.00177498 -0.0010139  -0.01342894 -0.03576367 -0.00017355\n",
      "   0.00069918 -0.00032258 -0.00022095 -0.0025484  -0.00026382 -0.00025873\n",
      "   0.00528214]\n",
      " [ 0.00437129 -0.00065068  0.00083517  0.01037445  0.02953448  0.00127795\n",
      "   0.00169908  0.00017048  0.00100466 -0.00351391  0.00081929  0.00217356\n",
      "  -0.00444829]\n",
      " [ 0.00101872  0.00242846  0.00017175  0.00304749  0.00622217 -0.00109735\n",
      "  -0.00240502  0.00014509 -0.00077667  0.00606926 -0.00054842 -0.00190777\n",
      "  -0.00082685]]\n",
      "[[-5.33360381e-03 -1.71453121e-03 -9.51778290e-04 -1.34070129e-02\n",
      "  -3.57004324e-02 -1.09953167e-04  6.42065745e-04 -2.60168418e-04\n",
      "  -1.63239940e-04 -2.49971211e-03 -2.00046359e-04 -1.95933741e-04\n",
      "   5.28919280e-03]\n",
      " [ 4.29420476e-03 -6.12910720e-04  7.68550884e-04  1.02955604e-02\n",
      "   2.94941734e-02  1.21474738e-03  1.63287857e-03  1.05496142e-04\n",
      "   9.45732559e-04 -3.45916420e-03  7.54597048e-04  2.10994102e-03\n",
      "  -4.42058000e-03]\n",
      " [ 9.69253583e-04  2.35732545e-03  1.12729165e-04  3.04096564e-03\n",
      "   6.13652321e-03 -1.03447805e-03 -2.34544256e-03  8.42309343e-05\n",
      "  -7.12119556e-04  6.02906324e-03 -4.84075207e-04 -1.84361145e-03\n",
      "  -7.98467335e-04]]\n",
      "[[-4.77467256e-03 -1.10143230e-03 -3.27444658e-04 -1.28968401e-02\n",
      "  -3.55696044e-02  0.00000000e+00  5.53122150e-05  0.00000000e+00\n",
      "   0.00000000e+00 -1.87391770e-03  0.00000000e+00  0.00000000e+00\n",
      "   5.42074449e-03]\n",
      " [ 3.70169883e-03 -1.67052401e-04  1.38733741e-04  9.71803246e-03\n",
      "   2.90863664e-02  5.86776739e-04  9.99154184e-04  0.00000000e+00\n",
      "   3.18600593e-04 -2.83322309e-03  1.25460044e-04  1.48796737e-03\n",
      "  -4.16168278e-03]\n",
      " [ 3.69584497e-04  1.74439657e-03  0.00000000e+00  2.47541836e-03\n",
      "   5.77996260e-03 -3.96329364e-04 -1.70767026e-03  0.00000000e+00\n",
      "  -7.51257608e-05  5.41172548e-03  0.00000000e+00 -1.20804160e-03\n",
      "  -5.58631243e-04]]\n"
     ]
    }
   ],
   "source": [
    "#L1의 규제강도 C를 바꿔가며 계수 추정치 관찰\n",
    "print(lr1_10.intercept_)\n",
    "print(lr1_1.intercept_)\n",
    "print(lr1_0_1.intercept_)\n",
    "\n",
    "print(lr1_10.coef_)\n",
    "print(lr1_1.coef_)\n",
    "print(lr1_0_1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
