# Crawling and word-cloud

## Crawling
<img src="https://user-images.githubusercontent.com/53554014/86812486-0c3d1080-c0ba-11ea-8524-6f0f670649ec.png" width="40%" height="40%" title="news start HTML"></img>
<img src="https://user-images.githubusercontent.com/53554014/86812534-152de200-c0ba-11ea-9ea3-7347736f59ff.png" width="40%" height="40%" title="news end HTML"></img>
### Pre-requisties
|  <center>Requirement</center> |  <center>Description</center> |  
|:--------|:--------:|
|**Python** | <center>v3.X or higher</center> |
|**pip** | <center>We use pip install command to install python package</center> |
 
### Installation
```
pip install beautifulsoup4
```
- This is needed to analysis HTML, XML, JSON
```
pip install requests
```
- This is needed to request HTTP
***
## Word-cloud
![wc](https://user-images.githubusercontent.com/53554014/86812197-b2d4e180-c0b9-11ea-82d8-4688c1ae6788.png)
### Pre-requisties
|  <center>Requirement</center> |  <center>Description</center> |  
|:--------|:--------:|
|**Python** | <center>v3.X or higher</center> |
|**pip** | <center>We use pip install command to install python package</center> |
 
### Installation
```
pip install eunjeon
```
- This is needed to extract Korean morpheme. I use mecab from [pyeunjeon](https://github.com/koshort/pyeunjeon)

```
pip install wordcloud
```
- This is needed to create word cloud

